#!/usr/bin/env python3
"""
Full Calibration Pipeline with All Available Targets

Calibrates CPS microdata to match official Census/IRS targets:
- 51 state populations (324M total)
- 18 age brackets × 51 states = 918 granular age targets
- 7 AGI brackets × 51 states = 357 income distribution targets
- 3 filing status categories
- Benefit program totals (SNAP, Medicaid, SSI)

Target count: ~1,400+ constraints
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import numpy as np
import pandas as pd
from microplex.calibration import Calibrator

# State FIPS to abbreviation mapping
FIPS_TO_STATE = {
    1: "AL", 2: "AK", 4: "AZ", 5: "AR", 6: "CA", 8: "CO", 9: "CT", 10: "DE",
    11: "DC", 12: "FL", 13: "GA", 15: "HI", 16: "ID", 17: "IL", 18: "IN",
    19: "IA", 20: "KS", 21: "KY", 22: "LA", 23: "ME", 24: "MD", 25: "MA",
    26: "MI", 27: "MN", 28: "MS", 29: "MO", 30: "MT", 31: "NE", 32: "NV",
    33: "NH", 34: "NJ", 35: "NM", 36: "NY", 37: "NC", 38: "ND", 39: "OH",
    40: "OK", 41: "OR", 42: "PA", 44: "RI", 45: "SC", 46: "SD", 47: "TN",
    48: "TX", 49: "UT", 50: "VT", 51: "VA", 53: "WA", 54: "WV", 55: "WI",
    56: "WY",
}
STATE_TO_FIPS = {v: k for k, v in FIPS_TO_STATE.items()}

# AGI brackets (matching IRS SOI)
AGI_BRACKETS = [
    ("0_25k", 0, 25000),
    ("25k_50k", 25000, 50000),
    ("50k_75k", 50000, 75000),
    ("75k_100k", 75000, 100000),
    ("100k_200k", 100000, 200000),
    ("200k_500k", 200000, 500000),
    ("500k_plus", 500000, float('inf')),
]

# Age brackets (matching Census)
AGE_BRACKETS = [
    ("0_5", 0, 5), ("5_10", 5, 10), ("10_15", 10, 15), ("15_20", 15, 20),
    ("20_25", 20, 25), ("25_30", 25, 30), ("30_35", 30, 35), ("35_40", 35, 40),
    ("40_45", 40, 45), ("45_50", 45, 50), ("50_55", 50, 55), ("55_60", 55, 60),
    ("60_65", 60, 65), ("65_70", 65, 70), ("70_75", 70, 75), ("75_80", 75, 80),
    ("80_85", 80, 85), ("85_plus", 85, 200),
]


def load_enhanced_cps(data_dir: Path) -> pd.DataFrame:
    """Load enhanced CPS with filing status."""
    print("=" * 70)
    print("LOADING ENHANCED CPS DATA")
    print("=" * 70)

    df = pd.read_parquet(data_dir / "cps_enhanced_for_calibration.parquet")
    print(f"Records: {len(df):,}")
    print(f"Columns: {df.columns.tolist()}")

    # Filter territories
    territory_fips = {3, 7, 14, 43, 52}
    df = df[~df['state_fips'].isin(territory_fips)].copy()
    print(f"After filtering territories: {len(df):,}")

    return df


def build_household_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """Build all household-level indicators for calibration."""
    print("\n" + "=" * 70)
    print("BUILDING HOUSEHOLD INDICATORS")
    print("=" * 70)

    # Aggregate to household level
    hh_cols = ['household_id', 'state_fips', 'tenure', 'hh_weight', 'n_persons', 'n_children', 'n_adults']
    hh = df[hh_cols].drop_duplicates('household_id').copy()

    print(f"Households: {len(hh):,}")

    # 1. State × person count indicators
    print("\n1. State person indicators...")
    for fips in sorted(hh['state_fips'].unique()):
        state = FIPS_TO_STATE.get(int(fips), str(fips))
        col = f"n_persons_state_{state}"
        hh[col] = np.where(hh['state_fips'] == fips, hh['n_persons'], 0)

    # 2. Age group indicators (aggregate from persons)
    print("2. Age group indicators...")
    for bracket_name, age_min, age_max in AGE_BRACKETS:
        mask = (df['age'] >= age_min) & (df['age'] < age_max)
        counts = df[mask].groupby('household_id').size()
        col = f"n_age_{bracket_name}"
        hh[col] = hh['household_id'].map(counts).fillna(0).astype(int)

    # Broad age groups for compatibility
    hh['n_age_0_17'] = hh[[f'n_age_{b[0]}' for b in AGE_BRACKETS if b[2] <= 20]].sum(axis=1)
    hh['n_age_18_64'] = hh[[f'n_age_{b[0]}' for b in AGE_BRACKETS if b[1] >= 20 and b[2] <= 65]].sum(axis=1)
    hh['n_age_65_plus'] = hh[[f'n_age_{b[0]}' for b in AGE_BRACKETS if b[1] >= 65]].sum(axis=1)

    # 3. AGI bracket indicators (using household income)
    print("3. AGI bracket indicators...")
    hh_income = df.groupby('household_id')['income'].sum()
    hh['hh_income'] = hh['household_id'].map(hh_income).fillna(0)

    for bracket_name, agi_min, agi_max in AGI_BRACKETS:
        mask = (hh['hh_income'] >= agi_min) & (hh['hh_income'] < agi_max)
        col = f"n_agi_{bracket_name}"
        hh[col] = mask.astype(int)

    # 4. State × AGI bracket indicators
    print("4. State × AGI bracket indicators...")
    for fips in sorted(hh['state_fips'].unique()):
        state = FIPS_TO_STATE.get(int(fips), str(fips))
        state_mask = hh['state_fips'] == fips
        for bracket_name, agi_min, agi_max in AGI_BRACKETS:
            agi_mask = (hh['hh_income'] >= agi_min) & (hh['hh_income'] < agi_max)
            col = f"n_returns_{state}_{bracket_name}"
            hh[col] = (state_mask & agi_mask).astype(int)

    # 5. Filing status indicators (aggregate from tax units)
    print("5. Filing status indicators...")
    # Count tax units by filing status per household
    for status in ['single', 'married_joint', 'head_of_household']:
        mask = df['filing_status'] == status
        # Count unique tax units with this status per household
        counts = df[mask].groupby('household_id')['tax_unit_id'].nunique()
        col = f"n_filing_{status}"
        hh[col] = hh['household_id'].map(counts).fillna(0).astype(int)

    indicator_cols = [c for c in hh.columns if c.startswith('n_')]
    print(f"\nCreated {len(indicator_cols)} indicator columns")

    return hh


def load_and_parse_targets(data_dir: Path) -> dict:
    """Load all calibration targets from official sources."""
    print("\n" + "=" * 70)
    print("LOADING OFFICIAL TARGETS")
    print("=" * 70)

    targets_df = pd.read_parquet(data_dir / "targets.parquet")
    print(f"Loaded {len(targets_df):,} raw targets")

    targets = {}

    # 1. State populations from age distribution
    print("\n1. Parsing state population targets...")
    state_pop = {}
    state_age = {}  # state -> age_bracket -> count

    for _, row in targets_df.iterrows():
        name = row['name']
        value = row['value']

        if name.startswith('pop_') and '_age_' in name:
            parts = name.split('_age_')
            state = name.split('_')[1]
            age_bracket = parts[1]

            if state not in state_pop:
                state_pop[state] = 0
                state_age[state] = {}
            state_pop[state] += value
            state_age[state][age_bracket] = value

    # Add state population targets
    for state, pop in state_pop.items():
        if state in STATE_TO_FIPS:
            targets[f"n_persons_state_{state}"] = pop

    print(f"  States: {len(state_pop)}")
    print(f"  Total population: {sum(state_pop.values()):,.0f}")

    # 2. Granular age targets (sum across states)
    print("\n2. Parsing age bracket targets...")
    age_totals = {}
    for state, ages in state_age.items():
        for age_bracket, count in ages.items():
            if age_bracket not in age_totals:
                age_totals[age_bracket] = 0
            age_totals[age_bracket] += count

    for age_bracket, count in age_totals.items():
        targets[f"n_age_{age_bracket}"] = count

    print(f"  Age brackets: {len(age_totals)}")

    # 3. State × AGI bracket targets
    print("\n3. Parsing state × AGI targets...")
    agi_count = 0
    for _, row in targets_df.iterrows():
        name = row['name']
        if name.startswith('returns_'):
            # Parse "returns_CA_0_25k" format
            parts = name.replace('returns_', '').split('_', 1)
            if len(parts) == 2:
                state, bracket = parts[0], parts[1]
                if state in STATE_TO_FIPS:
                    targets[f"n_returns_{state}_{bracket}"] = row['value']
                    agi_count += 1

    print(f"  State × AGI targets: {agi_count}")

    # 4. Filing status targets
    print("\n4. Parsing filing status targets...")
    fs_map = {
        'tax_returns_single': 'n_filing_single',
        'tax_returns_married_joint': 'n_filing_married_joint',
        'tax_returns_head_of_household': 'n_filing_head_of_household',
    }
    for src, dst in fs_map.items():
        row = targets_df[targets_df['name'] == src]
        if len(row) > 0:
            targets[dst] = row['value'].iloc[0]
            print(f"  {dst}: {targets[dst]:,.0f}")

    # 5. Benefit program targets
    print("\n5. Parsing benefit program targets...")
    benefit_map = {
        'snap_recipients': 'n_snap_recipients',
        'medicaid_enrollees': 'n_medicaid_enrollees',
        'ssi_recipients': 'n_ssi_recipients',
        'housing_assistance': 'n_housing_assistance',
    }
    for src, dst in benefit_map.items():
        row = targets_df[targets_df['name'] == src]
        if len(row) > 0:
            # Skip benefit targets for now - need benefit indicators in CPS
            print(f"  {src}: {row['value'].iloc[0]:,.0f} (skipped - no CPS indicator)")

    print(f"\n=== TOTAL USABLE TARGETS: {len(targets):,} ===")

    return targets


def filter_targets_to_data(targets: dict, hh: pd.DataFrame) -> dict:
    """Keep only targets that have corresponding indicators in data."""
    available = set(hh.columns)
    filtered = {k: v for k, v in targets.items() if k in available}

    missing = set(targets.keys()) - set(filtered.keys())
    if missing:
        print(f"\nDropped {len(missing)} targets without data indicators")

    return filtered


def run_calibration(hh: pd.DataFrame, targets: dict) -> pd.DataFrame:
    """Run IPF calibration with all targets."""
    print("\n" + "=" * 70)
    print("RUNNING CALIBRATION")
    print("=" * 70)

    hh = hh.copy()
    hh['weight'] = hh['hh_weight']

    print(f"Continuous constraints: {len(targets)}")

    # Group targets by type for display
    state_targets = {k: v for k, v in targets.items() if 'state_' in k}
    age_targets = {k: v for k, v in targets.items() if k.startswith('n_age_')}
    agi_targets = {k: v for k, v in targets.items() if 'returns_' in k}
    filing_targets = {k: v for k, v in targets.items() if 'filing_' in k}

    print(f"  State populations: {len(state_targets)}")
    print(f"  Age brackets: {len(age_targets)}")
    print(f"  State × AGI: {len(agi_targets)}")
    print(f"  Filing status: {len(filing_targets)}")

    calibrator = Calibrator(
        method="ipf",
        max_iter=200,
        tol=1e-6,
    )

    calibrator.fit(
        hh,
        marginal_targets={},
        continuous_targets=targets,
        weight_col="weight",
    )

    hh['calibrated_weight'] = calibrator.weights_

    print(f"\nCalibration complete!")
    print(f"  Converged: {calibrator.converged_}")
    print(f"  Iterations: {calibrator.n_iterations_}")

    weight_ratio = hh['calibrated_weight'] / hh['weight']
    print(f"\nWeight adjustment statistics:")
    print(f"  Min ratio: {weight_ratio.min():.4f}")
    print(f"  Max ratio: {weight_ratio.max():.4f}")
    print(f"  Mean ratio: {weight_ratio.mean():.4f}")
    print(f"  Std ratio: {weight_ratio.std():.4f}")

    return hh


def validate_and_report(hh: pd.DataFrame, targets: dict):
    """Validate calibration results."""
    print("\n" + "=" * 70)
    print("VALIDATION REPORT")
    print("=" * 70)

    errors = []
    for var, target in sorted(targets.items()):
        actual = (hh[var] * hh['calibrated_weight']).sum()
        error = abs(actual - target) / target * 100 if target > 0 else 0
        errors.append((var, target, actual, error))

    # Summary by category
    state_errors = [e for e in errors if 'state_' in e[0]]
    age_errors = [e for e in errors if e[0].startswith('n_age_')]
    agi_errors = [e for e in errors if 'returns_' in e[0]]
    filing_errors = [e for e in errors if 'filing_' in e[0]]

    print(f"\nState populations ({len(state_errors)} targets):")
    print(f"  Max error: {max(e[3] for e in state_errors):.4f}%")
    print(f"  Avg error: {np.mean([e[3] for e in state_errors]):.4f}%")

    print(f"\nAge brackets ({len(age_errors)} targets):")
    print(f"  Max error: {max(e[3] for e in age_errors):.4f}%")
    print(f"  Avg error: {np.mean([e[3] for e in age_errors]):.4f}%")

    if agi_errors:
        print(f"\nState × AGI ({len(agi_errors)} targets):")
        print(f"  Max error: {max(e[3] for e in agi_errors):.4f}%")
        print(f"  Avg error: {np.mean([e[3] for e in agi_errors]):.4f}%")

    if filing_errors:
        print(f"\nFiling status ({len(filing_errors)} targets):")
        for var, target, actual, error in filing_errors:
            print(f"  {var}: target={target:,.0f}, actual={actual:,.0f}, error={error:.2f}%")

    # Overall
    total_error = np.mean([e[3] for e in errors])
    print(f"\n=== OVERALL MEAN ERROR: {total_error:.4f}% ===")

    # Top 10 worst targets
    worst = sorted(errors, key=lambda x: x[3], reverse=True)[:10]
    print(f"\nTop 10 highest error targets:")
    for var, target, actual, error in worst:
        print(f"  {var}: {error:.2f}% (target={target:,.0f}, actual={actual:,.0f})")


def main():
    """Run full calibration pipeline."""
    print("=" * 70)
    print("MICROPLEX FULL CALIBRATION PIPELINE")
    print("=" * 70)

    data_dir = Path(__file__).parent.parent / "data"

    # Step 1: Load enhanced CPS
    df = load_enhanced_cps(data_dir)

    # Step 2: Build household indicators
    hh = build_household_indicators(df)

    # Step 3: Load and parse targets
    targets = load_and_parse_targets(data_dir)

    # Step 4: Filter targets to available indicators
    targets = filter_targets_to_data(targets, hh)
    print(f"\nFiltered to {len(targets)} usable targets")

    # Step 5: Run calibration
    hh = run_calibration(hh, targets)

    # Step 6: Validate
    validate_and_report(hh, targets)

    # Step 7: Save
    print("\n" + "=" * 70)
    print("SAVING OUTPUTS")
    print("=" * 70)

    output_path = data_dir / "microplex_calibrated_full.parquet"
    hh.to_parquet(output_path, index=False)
    print(f"Saved to {output_path}")

    print("\n" + "=" * 70)
    print("PIPELINE COMPLETE")
    print("=" * 70)
    print(f"\nFinal statistics:")
    print(f"  Households: {len(hh):,}")
    print(f"  Total weighted HHs: {hh['calibrated_weight'].sum():,.0f}")
    weighted_persons = (hh['n_persons'] * hh['calibrated_weight']).sum()
    print(f"  Total weighted persons: {weighted_persons:,.0f}")
    print(f"  Targets matched: {len(targets)}")

    return hh, targets


if __name__ == "__main__":
    hh, targets = main()
